{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_text_splitters import TokenTextSplitter, RecursiveCharacterTextSplitter\n",
    "from neo4j.exceptions import ClientError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init our tools - LLM and Graph database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xfG1Z0WseTkszMidYnnyfrN0OTn6xkM-u03K31q691w\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "# Connect to Neo4j Aura\n",
    "uri = \"neo4j+s://1b2ebe15.databases.neo4j.io\"\n",
    "username = \"neo4j\"\n",
    "password = 'xfG1Z0WseTkszMidYnnyfrN0OTn6xkM-u03K31q691w'\n",
    "print(password)\n",
    "\n",
    "graph = Neo4jGraph(uri, username, password)\n",
    "\n",
    "# Embeddings & LLM models\n",
    "embeddings = OpenAIEmbeddings()\n",
    "embedding_dimension = 1536\n",
    "llm = ChatOpenAI(model=\"gpt-4o-2024-08-06\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the text from PDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from langchain_core.documents.base import Document\n",
    "\n",
    "def docs_to_json_pretty(docs: List[Document]):\n",
    "    return json.dumps([doc.dict() for doc in docs], indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymupdf4llm in c:\\projects\\langchain\\venv\\lib\\site-packages (0.0.17)\n",
      "Requirement already satisfied: pymupdf>=1.24.10 in c:\\projects\\langchain\\venv\\lib\\site-packages (from pymupdf4llm) (1.24.12)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Processing menu.pdf...\n",
      "[                                        ] (0/6=====[======                                  ] (1/6======[=============                           ] (2/======[====================                    ] (3/6=====[==========================              ] (4/6======[=================================       ] (5/======[========================================] (6/6]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13610"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pip install pymupdf4llm\n",
    "import pymupdf4llm\n",
    "\n",
    "md_text = pymupdf4llm.to_markdown(\"menu.pdf\")\n",
    "\n",
    "# now work with the markdown text, e.g. store as a UTF8-encoded file\n",
    "import pathlib\n",
    "pathlib.Path(\"dinner.md\").write_bytes(md_text.encode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'APPETIZERS, SOUP & SALAD, PASTA, ENTRÉES, SIDES, PIZZAS, PERSONALIZED PIES'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "\n",
    "headers_to_split_on = [\n",
    "    (\"###\", \"Category\"),\n",
    "]\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on)\n",
    "md_header3_splits = markdown_splitter.split_text(md_text)\n",
    "categories = [split.metadata['Category'] for split in md_header3_splits if 'Category' in split.metadata]\n",
    "categories_str = ', '.join(categories)\n",
    "categories_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERSONALIZED PIES\n",
      "###### PLAIN CHEESE  \n",
      "ADDITIONAL TOPPINGS  \n",
      "###### MEDIUM . . . . . . . . . . . $12  \n",
      "MEDIUM . . . . . . $2 EACH  \n",
      "###### LARGE. . . . . . . . . . . $15  \n",
      "LARGE. . . . . . $4 EACH  \n",
      "###### Pepperoni | Crushed Garlic | Chicken Breast Anchovies | Spinach | Gorgonzola Italian Sausage | Ricotta Cheese | Pesto Artichoke Hearts | Prosciutto | Black Olives | Green Peppers White Mushrooms | Red Onions  \n",
      "We are happy to accommodate certain modifications but they may incur an additional charge  \n",
      "A $3.00 split fee is assessed for all shared items. Large pizzas and family items are not valid with discount cards.  \n",
      "There is a $3 per person dessert fee for any outside desserts, and a $30 corkage fee.  \n",
      "-----  \n",
      "## Welcome to Mama Ricotta’s  \n",
      "I opened Mama Ricotta’s in August of 1992 to offer the delicious homestyle Italian-American food I remember fondly from  \n",
      "my youth. Back in 1908, my grandfather emigrated from Quindice, Italy to Springfield, Massachusetts to find work as a  \n",
      "stonemason. He settled in Springfield’s South End, an ethnic neighborhood full of immigrants from all regions of Italy. Over  \n",
      "the years, natives of Naples, Calabria, Marche, Bari, and other regions joined our extended family through marriages and  \n",
      "friendships. I have chosen a regional Italian-American menu at Mama Ricotta’s because it reflects my family’s expansive  \n",
      "and diverse heritage.  \n",
      "We serve my interpretation of the dishes prepared by relatives and friends, who loved nothing more than to get together  \n",
      "to share new recipes and to perfect old favorites. The food here is created with the same passion and adventurous spirit I  \n",
      "saw every day in my family’s kitchen. Maybe it goes without saying, but family and friends deserve only the best. It was  \n",
      "true when I was a boy in Springfield, and it’s true every time a guest walks through the door of Mama Ricotta’s. We seek  \n",
      "out the finest and freshest ingredients from across the globe, and hold the highest standards for our homemade  \n",
      "mozzarella, sausage, breads, and desserts. One dish at a time, it’s my pleasure to continue a rich tradition of quality,  \n",
      "creativity and warm hospitality.  \n",
      "##### So please relax and enjoy. We’re glad to have you here.  \n",
      "Frank Scibelli  \n",
      "Restaurant | P. 704.343.0148 Catering | P. 704.343.0155\n",
      "601 South Kings Drive • Suite AA Charlotte, NC 28204  \n",
      "##### Frank Scibelli  \n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "i=7\n",
    "print(md_header3_splits[i].metadata[\"Category\"])\n",
    "print(md_header3_splits[i].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Plumbing for Jeopardy Questions with Points and Answers in Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JeopardyQuestion(BaseModel):\n",
    "    \"\"\"Structuring questions with categories, points, and answers.\"\"\"\n",
    "    category: str = Field(..., description=\"Jeopardy-style category\")\n",
    "    question: str = Field(..., description=\"Generated question\")\n",
    "    answer: str = Field(..., description=\"Generated answer\")\n",
    "    points: int = Field(..., description=\"Point value associated with the question\")\n",
    "\n",
    "class JeopardyQuestions(BaseModel):\n",
    "    \"\"\"Generating hypothetical Jeopardy-style questions with answers.\"\"\"\n",
    "    questions: List[JeopardyQuestion] = Field(\n",
    "        ..., description=\"List of questions with their categories, answers, and points\"\n",
    "    )\n",
    "\n",
    "questions_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            (\n",
    "                f\"You are generating Jeopardy-style questions with points and answers in the following categories {categories_str}\"\n",
    "                \"based on the information found in the text. \"\n",
    "                \"Each question should have only one correct answer and a corresponding category. \"\n",
    "                \"Each question should have a point value ranging from 100 to 500 depending on the difficulty of the question. \"\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            (\n",
    "                \"Use the given format to generate Jeopardy-style questions with difficulty point value and answers in corresponding category from the \"\n",
    "                \"following input: {input}\"\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_chain = questions_prompt | llm.with_structured_output(JeopardyQuestions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.query(\"match (n:Chunk|Question|Answer|Category) detach delete n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate and Ingest Questions with Points and Answers for Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk_id, chunk in enumerate(md_header3_splits):\n",
    "    # ignore document sections that do not have a category\n",
    "    if \"Category\" not in chunk.metadata:\n",
    "        continue\n",
    "\n",
    "    jeopardy_data = question_chain.invoke(chunk.page_content)\n",
    "    questions = jeopardy_data.questions\n",
    "    # print(docs_to_json_pretty(questions))\n",
    "\n",
    "    params = {\n",
    "        \"chunk_id\": chunk_id,\n",
    "        \"questions\": [\n",
    "            {\n",
    "                \"question_id\": f\"c-{chunk_id}-q-{question_id}\",\n",
    "                \"text\": q.question,\n",
    "                \"category_id\": f\"c-{chunk_id}-cat-{categories.index(q.category)}\",\n",
    "                \"category_name\": q.category,\n",
    "                \"points\": q.points,\n",
    "                \"question_embedding\": embeddings.embed_query(q.question),\n",
    "                \"answer_id\": f\"c-{chunk_id}-a-{question_id}\",\n",
    "                \"answer_text\": q.answer,\n",
    "                \"answer_embedding\": embeddings.embed_query(q.answer)\n",
    "            }\n",
    "            for question_id, q in enumerate(questions)\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    # print(json.dumps(params, indent=4))\n",
    "\n",
    "    # create question nodes\n",
    "    graph.query(\n",
    "        \"\"\"\n",
    "        UNWIND $questions AS question\n",
    "        MERGE (chunk:Chunk {id: $chunk_id})\n",
    "        WITH chunk, question\n",
    "        MERGE (cat:Category {id: question.category_id, name: question.category_name})\n",
    "        WITH chunk, cat, question\n",
    "        CREATE (q:Question {id: question.question_id})\n",
    "        CREATE (a:Answer {id: question.answer_id})\n",
    "        SET q.text = question.text, q.points = question.points\n",
    "        SET a.text = question.answer_text\n",
    "        MERGE (cat)<-[:IN_CATEGORY]-(q)-[:FOR_CONTENT]->(chunk)\n",
    "        MERGE (q)-[:HAS_ANSWER]->(a)\n",
    "\n",
    "        WITH q, question\n",
    "\n",
    "        CALL db.create.setVectorProperty(q, 'embedding', question.question_embedding) \n",
    "        YIELD node\n",
    "        RETURN count(*)\n",
    "    \"\"\",\n",
    "        params,\n",
    "    )\n",
    "\n",
    "    # Set vector embedding for answers\n",
    "    graph.query(\n",
    "        \"\"\"\n",
    "        UNWIND $questions AS question\n",
    "        MATCH (a:Answer {id: question.answer_id})\n",
    "        WITH a, question\n",
    "\n",
    "        CALL db.create.setVectorProperty(a, 'embedding', question.answer_embedding) \n",
    "        YIELD node\n",
    "        RETURN count(*)\n",
    "        \"\"\",\n",
    "        params,\n",
    "    )\n",
    "    \n",
    "    # Create vector indexes for questions\n",
    "    try:\n",
    "        graph.query(\n",
    "            \"CALL db.index.vector.createNodeIndex('jeopardy_questions', \"\n",
    "            \"'Question', 'embedding', $dimension, 'cosine')\",\n",
    "            {\"dimension\": embedding_dimension},\n",
    "        )\n",
    "    except ClientError:  # already exists\n",
    "        pass\n",
    "\n",
    "    # Create vector indexes for answers\n",
    "    try:\n",
    "        graph.query(\n",
    "            \"CALL db.index.vector.createNodeIndex('jeopardy_answers', \"\n",
    "            \"'Answer', 'embedding', $dimension, 'cosine')\",\n",
    "            {\"dimension\": embedding_dimension},\n",
    "        )\n",
    "    except ClientError:  # already exists\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textdistance\n",
      "  Downloading textdistance-4.6.3-py3-none-any.whl (31 kB)\n",
      "Installing collected packages: textdistance\n",
      "Successfully installed textdistance-4.6.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Fontina cheese cheese 0.41269841269841273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_user_answer_using_neo4j(user_answer, question_id):\n",
    "    user_answer_embedding = embeddings.embed_query(user_answer)\n",
    "    params = {\n",
    "        \"user_answer_embedding\":user_answer_embedding, \n",
    "        \"question_id\":question_id,\n",
    "        \"user_answer\": user_answer\n",
    "    }\n",
    "\n",
    "    cosine_similarity_query = \"\"\"\n",
    "    WITH $user_answer_embedding AS user_embedding  \n",
    "    MATCH (q:Question {id: $question_id})-[:HAS_ANSWER]->(a:Answer)\n",
    "    WITH user_embedding, a, a.embedding AS answer_embedding\n",
    "    RETURN a.text AS answerText, \n",
    "        gds.similarity.cosine(user_embedding, answer_embedding) AS similarity\n",
    "    \"\"\"\n",
    "\n",
    "    jaro_winkler_distance_query = \"\"\"\n",
    "    WITH $user_answer AS user_answer\n",
    "    MATCH (q:Question {id: $question_id})-[:HAS_ANSWER]->(a:Answer)\n",
    "    WITH a.text as correct_answer, user_answer\n",
    "    RETURN correct_answer, user_answer, \n",
    "        apoc.text.jaroWinklerDistance(correct_answer, user_answer) AS output\n",
    "    \"\"\"\n",
    "\n",
    "    result = graph.query(jaro_winkler_distance_query, params)\n",
    "\n",
    "    print(result)\n",
    "\n",
    "    return None\n",
    "\n",
    "%pip install textdistance\n",
    "import textdistance as td\n",
    "def check_user_answer_using_td(user_answer, question_id):\n",
    "    params = {\n",
    "        \"question_id\":question_id,\n",
    "        \"user_answer\": user_answer\n",
    "    }\n",
    "    get_correct_answer_query = \"\"\"\n",
    "    MATCH (q:Question {id: $question_id})-[:HAS_ANSWER]->(a:Answer)\n",
    "    RETURN a.text AS correct_answer\n",
    "    \"\"\"\n",
    "    result = graph.query(get_correct_answer_query, params)\n",
    "    distance_similarity = td.jaro_winkler(result[0][\"correct_answer\"], user_answer)\n",
    "    print(result[0][\"correct_answer\"], user_answer, distance_similarity)\n",
    "    return  distance_similarity > 0.8\n",
    "\n",
    "\n",
    "# check_user_answer(\"lettuce\", \"c-2-q-3\")\n",
    "check_user_answer_using_td(\"cheese\", \"c-2-q-1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.5\n",
      "0.8333333333333334\n",
      "0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "import textdistance as td\n",
    "def print_distance(answer, user_answer):\n",
    "    print(td.levenshtein.normalized_similarity(answer, user_answer))\n",
    "    print(td.damerau_levenshtein.normalized_similarity(answer, user_answer))\n",
    "    print(td.jaro(answer, user_answer))\n",
    "    print(td.jaro_winkler(answer, user_answer))\n",
    "\n",
    "print_distance(\"$3\", \"$3.3\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
